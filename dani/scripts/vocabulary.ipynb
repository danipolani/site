{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef9a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 221 words\n",
      "starting generation\n",
      "generation done\n",
      "saving to csv: ../csv/lt/vocabulary.ru.csv\n",
      "saving to csv: ../csv/lt/vocabulary.en.csv\n",
      "saving done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "LETTERS_PATH = \"../csv/lt/transliterations.csv\"\n",
    "VOC_PATH = \"../csv/lt/vocabulary-source.csv\"\n",
    "RES_PATH_RU = \"../csv/lt/vocabulary.ru.csv\"\n",
    "RES_PATH_EN = \"../csv/lt/vocabulary.en.csv\"\n",
    "JSON_PATH = \"../data/lt/vocabulary-pregen.json\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _count_vowels(s):\n",
    "    vowels = \"aouie\"\n",
    "    c = 0\n",
    "    for l in s:\n",
    "        if l in vowels:\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def _to_lat(s, letters):\n",
    "    return letters[\"lat\"][s]\n",
    "\n",
    "def _word_to_lat(s, letters):\n",
    "    return \"\".join([_to_lat(l, letters) for l in s])\n",
    "\n",
    "def _to_ipa(s, letters):\n",
    "    return letters['ipa'][s]\n",
    "\n",
    "\n",
    "def _word_to_ipa(s, letters, stress=0):\n",
    "    if math.isnan(stress):\n",
    "        stress = 0\n",
    "    stress_marker = \"ˈ\"\n",
    "    if _count_vowels(s) < 2:\n",
    "        stress_marker = \"\"\n",
    "    res = \"\"\n",
    "    for i, l in enumerate(s):\n",
    "        if i == stress:\n",
    "            res += stress_marker\n",
    "        res += _to_ipa(l, letters)\n",
    "    return \"\".join(res)\n",
    "\n",
    "\n",
    "def _to_cyr(s, letters):\n",
    "    return letters['cyr'][s]\n",
    "\n",
    "\n",
    "def _word_to_cyr(s, letters):\n",
    "    return \"\".join([_to_cyr(l, letters) for l in s])\n",
    "\n",
    "\n",
    "def _finalize_lat(s):\n",
    "    s = re.sub(\"mj$\", \"m'\", s)\n",
    "    s = re.sub(\"lj$\", \"l'\", s)\n",
    "    s = re.sub(\"nj$\", \"n'\", s)\n",
    "    return s\n",
    "\n",
    "def _finalize_ipa(s):\n",
    "    s = re.sub(\"mj\", \"mʲ\", s)\n",
    "    s = re.sub(\"lj\", \"ʎ\", s)\n",
    "    s = re.sub(\"nj\", \"ɲ\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _finalize_cyr(s):\n",
    "    s = re.sub(\"йа\", \"я\", s)\n",
    "    s = re.sub(\"мй$\", \"мь\", s)\n",
    "    s = re.sub(\"лй$\", \"ль\", s)\n",
    "    s = re.sub(\"нй$\", \"нь\", s)\n",
    "    s = re.sub(\"^е\", \"э\", s)\n",
    "    return s\n",
    "\n",
    "def to_lat(s, letters):\n",
    "    return _finalize_lat(_word_to_lat(s, letters))\n",
    "               \n",
    "\n",
    "def to_cyr(s, letters):\n",
    "    return _finalize_cyr(_word_to_cyr(s, letters))\n",
    "\n",
    "\n",
    "def to_ipa(s, letters, stress=0):\n",
    "    return _finalize_ipa(_word_to_ipa(s, letters, stress))\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    letters = pd.read_csv(LETTERS_PATH).set_index(\"letter\").to_dict()\n",
    "    voc = pd.read_csv(VOC_PATH)\n",
    "    print(f\"loaded {voc.shape[0]} words\")\n",
    "\n",
    "    print(\"starting generation\")\n",
    "    voc[\"ipa\"] = voc.apply(lambda x: to_ipa(x.word, letters, x.stress), axis=1)\n",
    "    voc[\"cyr\"] = voc[\"word\"].apply(lambda x: to_cyr(x, letters))\n",
    "    voc[\"lat\"] = voc[\"word\"].apply(lambda x: to_lat(x, letters))\n",
    "    voc[\"head_cyr\"] = voc[\"cyr\"].apply(lambda x: x[0])\n",
    "    voc[\"head_lat\"] = voc[\"lat\"].apply(lambda x: x[0])\n",
    "    voc = voc.sort_values(by=['cyr'])\n",
    "    print(\"generation done\")\n",
    "\n",
    "    print(f\"saving to csv: {RES_PATH_RU}\")\n",
    "    voc[[\"word\", \"pos\", \"ipa\", \"cyr\", \"head_cyr\", \"ru\"]].sort_values(by=['cyr']).to_csv(RES_PATH_RU, index=False)\n",
    "    \n",
    "    print(f\"saving to csv: {RES_PATH_EN}\")\n",
    "    voc[[\"word\", \"pos\", \"ipa\", \"lat\", \"head_lat\", \"en\"]].sort_values(by=['lat']).to_csv(RES_PATH_EN, index=False)\n",
    "    print(\"saving done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "743d2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## А\n",
      "{{< lt/vocabulary-ru \"а\" >}}\n",
      "\n",
      "## Б\n",
      "{{< lt/vocabulary-ru \"б\" >}}\n",
      "\n",
      "## В\n",
      "{{< lt/vocabulary-ru \"в\" >}}\n",
      "\n",
      "## Г\n",
      "{{< lt/vocabulary-ru \"г\" >}}\n",
      "\n",
      "## Д\n",
      "{{< lt/vocabulary-ru \"д\" >}}\n",
      "\n",
      "## З\n",
      "{{< lt/vocabulary-ru \"з\" >}}\n",
      "\n",
      "## И\n",
      "{{< lt/vocabulary-ru \"и\" >}}\n",
      "\n",
      "## Й\n",
      "{{< lt/vocabulary-ru \"й\" >}}\n",
      "\n",
      "## К\n",
      "{{< lt/vocabulary-ru \"к\" >}}\n",
      "\n",
      "## Л\n",
      "{{< lt/vocabulary-ru \"л\" >}}\n",
      "\n",
      "## М\n",
      "{{< lt/vocabulary-ru \"м\" >}}\n",
      "\n",
      "## Н\n",
      "{{< lt/vocabulary-ru \"н\" >}}\n",
      "\n",
      "## О\n",
      "{{< lt/vocabulary-ru \"о\" >}}\n",
      "\n",
      "## П\n",
      "{{< lt/vocabulary-ru \"п\" >}}\n",
      "\n",
      "## Р\n",
      "{{< lt/vocabulary-ru \"р\" >}}\n",
      "\n",
      "## С\n",
      "{{< lt/vocabulary-ru \"с\" >}}\n",
      "\n",
      "## Т\n",
      "{{< lt/vocabulary-ru \"т\" >}}\n",
      "\n",
      "## У\n",
      "{{< lt/vocabulary-ru \"у\" >}}\n",
      "\n",
      "## Ш\n",
      "{{< lt/vocabulary-ru \"ш\" >}}\n",
      "\n",
      "## Э\n",
      "{{< lt/vocabulary-ru \"э\" >}}\n",
      "\n",
      "## Я\n",
      "{{< lt/vocabulary-ru \"я\" >}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in voc[\"head_cyr\"].sort_values().unique():\n",
    "    print(f\"## {c.upper()}\")\n",
    "    print('{{< lt/vocabulary-ru \"' + c + '\" >}}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45361fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## A\n",
      "{{< lt/vocabulary-en \"a\" >}}\n",
      "\n",
      "## B\n",
      "{{< lt/vocabulary-en \"b\" >}}\n",
      "\n",
      "## D\n",
      "{{< lt/vocabulary-en \"d\" >}}\n",
      "\n",
      "## E\n",
      "{{< lt/vocabulary-en \"e\" >}}\n",
      "\n",
      "## G\n",
      "{{< lt/vocabulary-en \"g\" >}}\n",
      "\n",
      "## I\n",
      "{{< lt/vocabulary-en \"i\" >}}\n",
      "\n",
      "## K\n",
      "{{< lt/vocabulary-en \"k\" >}}\n",
      "\n",
      "## L\n",
      "{{< lt/vocabulary-en \"l\" >}}\n",
      "\n",
      "## M\n",
      "{{< lt/vocabulary-en \"m\" >}}\n",
      "\n",
      "## N\n",
      "{{< lt/vocabulary-en \"n\" >}}\n",
      "\n",
      "## O\n",
      "{{< lt/vocabulary-en \"o\" >}}\n",
      "\n",
      "## P\n",
      "{{< lt/vocabulary-en \"p\" >}}\n",
      "\n",
      "## R\n",
      "{{< lt/vocabulary-en \"r\" >}}\n",
      "\n",
      "## S\n",
      "{{< lt/vocabulary-en \"s\" >}}\n",
      "\n",
      "## T\n",
      "{{< lt/vocabulary-en \"t\" >}}\n",
      "\n",
      "## U\n",
      "{{< lt/vocabulary-en \"u\" >}}\n",
      "\n",
      "## V\n",
      "{{< lt/vocabulary-en \"v\" >}}\n",
      "\n",
      "## Y\n",
      "{{< lt/vocabulary-en \"y\" >}}\n",
      "\n",
      "## Z\n",
      "{{< lt/vocabulary-en \"z\" >}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in voc[\"head_lat\"].sort_values().unique():\n",
    "    print(f\"## {c.upper()}\")\n",
    "    print('{{< lt/vocabulary-en \"' + c + '\" >}}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
